#!/usr/bin/env node

const fs = require('fs')
const path = require('path')

/**
 * åˆ†æé¡¹ç›®ä¸­çš„ç±»å‹ä½¿ç”¨æƒ…å†µ
 * æ£€æµ‹é‡å¤å®šä¹‰å’Œæœªä½¿ç”¨çš„ç±»å‹
 */

// éœ€è¦åˆ†æçš„æ ¸å¿ƒç±»å‹
const CORE_TYPES = [
  // åŸºç¡€ä¸šåŠ¡ç±»å‹
  'User',
  'Account',
  'Transaction',
  'Category',
  'Currency',
  'Tag',
  'UserSettings',
  'ExchangeRate',
  'Balance',
  'TrendDataPoint',

  // æ‰©å±•ä¸šåŠ¡ç±»å‹
  'RecurringTransaction',
  'LoanContract',
  'LoanPayment',
  'TransactionTemplate',

  // FIRE ç›¸å…³ç±»å‹
  'FireParams',
  'FireCalculationResult',
  'FireProjection',

  // æ™ºèƒ½ç²˜è´´ç›¸å…³ç±»å‹
  'SmartPasteRowData',
  'SmartPasteColumn',
  'SmartPasteGridConfig',
  'CellData',
  'CellPosition',
  'CellSelection',

  // è¡¨å•æ•°æ®ç±»å‹
  'TransactionFormData',
  'AccountFormData',
  'CategoryFormData',
  'TagFormData',
  'RecurringTransactionFormData',
  'LoanContractFormData',

  // ç»Ÿè®¡å’Œæ±‡æ€»ç±»å‹
  'CategoryStats',
  'AccountBalances',
  'CategorySummaryBase',
  'MonthlySummaryData',
  'AssetLiabilityData',

  // API ç›¸å…³ç±»å‹
  'ApiResponse',
  'ApiContext',
  'ApiHandler',
  'PaginatedResponse',

  // å¯¼å…¥å¯¼å‡ºç±»å‹
  'ExportedData',
  'ImportResult',
  'TransactionBatchResult',
]

// é¢œè‰²è¾“å‡ºå‡½æ•°
function colorize(text, color) {
  const colors = {
    red: '\x1b[31m',
    green: '\x1b[32m',
    yellow: '\x1b[33m',
    blue: '\x1b[34m',
    magenta: '\x1b[35m',
    cyan: '\x1b[36m',
    reset: '\x1b[0m',
  }
  return `${colors[color] || ''}${text}${colors.reset}`
}

// è·å–æ‰€æœ‰ TypeScript æ–‡ä»¶
function getAllTSFiles(dir, files = []) {
  const items = fs.readdirSync(dir)

  for (const item of items) {
    const fullPath = path.join(dir, item)
    const stat = fs.statSync(fullPath)

    if (stat.isDirectory()) {
      if (!['node_modules', '.next', 'dist', 'build', '.git'].includes(item)) {
        getAllTSFiles(fullPath, files)
      }
    } else if (item.endsWith('.ts') || item.endsWith('.tsx')) {
      files.push(fullPath)
    }
  }

  return files
}

// åˆ†ææ–‡ä»¶ä¸­çš„ç±»å‹å®šä¹‰
function analyzeTypeDefinitions(filePath) {
  const content = fs.readFileSync(filePath, 'utf8')
  const definitions = []

  // åŒ¹é… interface å®šä¹‰ - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ”¯æŒåµŒå¥—å¤§æ‹¬å·
  const interfaceRegex = /(?:export\s+)?interface\s+(\w+)(?:\s*<[^>]*>)?\s*(?:extends\s+[^{]+)?\s*{/g
  let match
  while ((match = interfaceRegex.exec(content)) !== null) {
    const typeName = match[1]
    const lineNumber = content.substring(0, match.index).split('\n').length

    // æ‰¾åˆ°å®Œæ•´çš„æ¥å£å®šä¹‰ï¼ˆå¤„ç†åµŒå¥—å¤§æ‹¬å·ï¼‰
    let braceCount = 1
    let endIndex = match.index + match[0].length
    while (braceCount > 0 && endIndex < content.length) {
      if (content[endIndex] === '{') braceCount++
      else if (content[endIndex] === '}') braceCount--
      endIndex++
    }

    const fullContent = content.substring(match.index, endIndex)
    definitions.push({
      type: 'interface',
      name: typeName,
      line: lineNumber,
      content: fullContent.length > 100 ? fullContent.substring(0, 100) + '...' : fullContent,
    })
  }

  // åŒ¹é… type å®šä¹‰ - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
  const typeRegex = /(?:export\s+)?type\s+(\w+)(?:\s*<[^>]*>)?\s*=/g
  while ((match = typeRegex.exec(content)) !== null) {
    const typeName = match[1]
    const lineNumber = content.substring(0, match.index).split('\n').length

    // æ‰¾åˆ°ç±»å‹å®šä¹‰çš„ç»“æŸä½ç½®
    let endIndex = match.index + match[0].length
    let depth = 0
    let inString = false
    let stringChar = ''

    while (endIndex < content.length) {
      const char = content[endIndex]

      if (!inString) {
        if (char === '"' || char === "'" || char === '`') {
          inString = true
          stringChar = char
        } else if (char === '{' || char === '[' || char === '(') {
          depth++
        } else if (char === '}' || char === ']' || char === ')') {
          depth--
        } else if (depth === 0 && (char === '\n' || char === ';')) {
          break
        }
      } else if (char === stringChar && content[endIndex - 1] !== '\\') {
        inString = false
      }

      endIndex++
    }

    const fullContent = content.substring(match.index, endIndex)
    definitions.push({
      type: 'type',
      name: typeName,
      line: lineNumber,
      content: fullContent.length > 100 ? fullContent.substring(0, 100) + '...' : fullContent,
    })
  }

  // åŒ¹é… enum å®šä¹‰
  const enumRegex = /(?:export\s+)?enum\s+(\w+)\s*{/g
  while ((match = enumRegex.exec(content)) !== null) {
    const typeName = match[1]
    const lineNumber = content.substring(0, match.index).split('\n').length

    // æ‰¾åˆ°å®Œæ•´çš„æšä¸¾å®šä¹‰
    let braceCount = 1
    let endIndex = match.index + match[0].length
    while (braceCount > 0 && endIndex < content.length) {
      if (content[endIndex] === '{') braceCount++
      else if (content[endIndex] === '}') braceCount--
      endIndex++
    }

    const fullContent = content.substring(match.index, endIndex)
    definitions.push({
      type: 'enum',
      name: typeName,
      line: lineNumber,
      content: fullContent.length > 100 ? fullContent.substring(0, 100) + '...' : fullContent,
    })
  }

  return definitions
}

// åˆ†æç±»å‹å¯¼å…¥
function analyzeTypeImports(filePath) {
  const content = fs.readFileSync(filePath, 'utf8')
  const imports = []

  // åŒ¹é… import type è¯­å¥ - æ”¯æŒå¤šè¡Œå’Œå¤æ‚æ ¼å¼
  const importTypeRegex = /import\s+type\s*{([^}]+)}\s+from\s+['"]([^'"]+)['"]/g
  let match
  while ((match = importTypeRegex.exec(content)) !== null) {
    const typesText = match[1]
    const source = match[2]

    // è§£æç±»å‹åç§°ï¼Œå¤„ç†åˆ«åå’Œæ¢è¡Œ
    const types = typesText
      .split(',')
      .map(t => t.trim())
      .map(t => {
        // å¤„ç† "Type as Alias" æ ¼å¼
        const asMatch = t.match(/^(.+?)\s+as\s+(.+)$/)
        return asMatch ? asMatch[2].trim() : t.trim()
      })
      .filter(t => t.length > 0)

    imports.push({ types, source, isTypeOnly: true })
  }

  // åŒ¹é…æ™®é€š import ä¸­çš„ç±»å‹
  const importRegex = /import\s*{([^}]+)}\s+from\s+['"]([^'"]+)['"]/g
  while ((match = importRegex.exec(content)) !== null) {
    const itemsText = match[1]
    const source = match[2]

    // è§£æå¯¼å…¥é¡¹
    const items = itemsText
      .split(',')
      .map(t => t.trim())
      .map(t => {
        // å¤„ç† "Item as Alias" æ ¼å¼
        const asMatch = t.match(/^(.+?)\s+as\s+(.+)$/)
        return asMatch ? asMatch[2].trim() : t.trim()
      })
      .filter(t => t.length > 0)

    // æ”¹è¿›çš„ç±»å‹æ£€æµ‹ï¼šå¤§å†™å¼€å¤´æˆ–åœ¨æ ¸å¿ƒç±»å‹åˆ—è¡¨ä¸­
    const types = items.filter(item => {
      return /^[A-Z]/.test(item) || CORE_TYPES.includes(item)
    })

    if (types.length > 0) {
      imports.push({ types, source, isTypeOnly: false })
    }
  }

  // åŒ¹é…é»˜è®¤å¯¼å…¥ä¸­çš„ç±»å‹ï¼ˆå¦‚æœæ˜¯å¤§å†™å¼€å¤´ï¼‰
  const defaultImportRegex = /import\s+(\w+)\s+from\s+['"]([^'"]+)['"]/g
  while ((match = defaultImportRegex.exec(content)) !== null) {
    const typeName = match[1]
    const source = match[2]

    if (/^[A-Z]/.test(typeName) || CORE_TYPES.includes(typeName)) {
      imports.push({ types: [typeName], source, isTypeOnly: false, isDefault: true })
    }
  }

  return imports
}

// ä¸»åˆ†æå‡½æ•°
function analyzeProject() {
  console.warn(colorize('ğŸ” TypeScript ç±»å‹ä½¿ç”¨åˆ†æå·¥å…·', 'blue'))
  console.warn('================================\n')

  const files = getAllTSFiles('src')
  const typeDefinitions = new Map() // typeName -> [{ file, line, content }]
  const typeImports = new Map() // typeName -> [{ file, source }]
  const fileAnalysis = []

  console.warn(colorize(`ğŸ“ åˆ†æ ${files.length} ä¸ªæ–‡ä»¶...`, 'cyan'))

  // åˆ†ææ¯ä¸ªæ–‡ä»¶
  files.forEach(file => {
    const definitions = analyzeTypeDefinitions(file)
    const imports = analyzeTypeImports(file)

    fileAnalysis.push({
      file,
      definitions,
      imports,
    })

    // æ”¶é›†ç±»å‹å®šä¹‰
    definitions.forEach(def => {
      if (!typeDefinitions.has(def.name)) {
        typeDefinitions.set(def.name, [])
      }
      typeDefinitions.get(def.name).push({
        file,
        line: def.line,
        content: def.content,
        type: def.type,
      })
    })

    // æ”¶é›†ç±»å‹å¯¼å…¥
    imports.forEach(imp => {
      imp.types.forEach(typeName => {
        if (!typeImports.has(typeName)) {
          typeImports.set(typeName, [])
        }
        typeImports.get(typeName).push({
          file,
          source: imp.source,
          isTypeOnly: imp.isTypeOnly,
        })
      })
    })
  })

  return { typeDefinitions, typeImports, fileAnalysis }
}

// åˆ†æç±»å‹ä¾èµ–å…³ç³»
function analyzeTypeDependencies(typeDefinitions, typeImports) {
  const dependencies = new Map() // typeName -> Set<dependentType>
  const reverseDependencies = new Map() // typeName -> Set<dependsOnType>

  // åˆ†ææ¯ä¸ªç±»å‹å®šä¹‰ä¸­å¼•ç”¨çš„å…¶ä»–ç±»å‹
  typeDefinitions.forEach((definitions, typeName) => {
    definitions.forEach(def => {
      const referencedTypes = new Set()

      // åœ¨ç±»å‹å®šä¹‰å†…å®¹ä¸­æŸ¥æ‰¾å…¶ä»–ç±»å‹çš„å¼•ç”¨
      CORE_TYPES.forEach(coreType => {
        if (coreType !== typeName && def.content.includes(coreType)) {
          referencedTypes.add(coreType)
        }
      })

      dependencies.set(typeName, referencedTypes)

      // å»ºç«‹åå‘ä¾èµ–å…³ç³»
      referencedTypes.forEach(refType => {
        if (!reverseDependencies.has(refType)) {
          reverseDependencies.set(refType, new Set())
        }
        reverseDependencies.get(refType).add(typeName)
      })
    })
  })

  return { dependencies, reverseDependencies }
}

// åˆ†ææœªä½¿ç”¨çš„ç±»å‹
function analyzeUnusedTypes(typeDefinitions, typeImports) {
  const unusedTypes = []

  typeDefinitions.forEach((definitions, typeName) => {
    const imports = typeImports.get(typeName) || []

    // å¦‚æœç±»å‹æœ‰å®šä¹‰ä½†æ²¡æœ‰å¯¼å…¥ä½¿ç”¨ï¼Œå¯èƒ½æ˜¯æœªä½¿ç”¨çš„
    if (definitions.length > 0 && imports.length === 0) {
      // æ£€æŸ¥æ˜¯å¦æ˜¯å¯¼å‡ºçš„ç±»å‹ï¼ˆå¯èƒ½è¢«å¤–éƒ¨ä½¿ç”¨ï¼‰
      const isExported = definitions.some(def =>
        def.content.includes('export interface') ||
        def.content.includes('export type') ||
        def.content.includes('export enum')
      )

      if (!isExported) {
        unusedTypes.push({
          typeName,
          definitions: definitions.map(def => ({
            file: def.file,
            line: def.line,
            type: def.type
          }))
        })
      }
    }
  })

  return unusedTypes
}

// ç”ŸæˆæŠ¥å‘Š
function generateReport() {
  const { typeDefinitions, typeImports } = analyzeProject()
  const dependencies = analyzeTypeDependencies(typeDefinitions, typeImports)
  const unusedTypes = analyzeUnusedTypes(typeDefinitions, typeImports)

  // ä½¿ç”¨ console.warn æ›¿ä»£ console.log ä»¥ç¬¦åˆ lint è§„åˆ™
  console.warn(colorize('\nğŸ“Š é‡å¤ç±»å‹å®šä¹‰åˆ†æ:', 'yellow'))
  console.warn('================================')

  // æŸ¥æ‰¾é‡å¤å®šä¹‰
  const duplicates = []
  typeDefinitions.forEach((definitions, typeName) => {
    if (definitions.length > 1) {
      duplicates.push({ typeName, definitions })
    }
  })

  if (duplicates.length === 0) {
    console.warn(colorize('âœ… æ²¡æœ‰å‘ç°é‡å¤çš„ç±»å‹å®šä¹‰ï¼', 'green'))
  } else {
    console.warn(
      colorize(`âŒ å‘ç° ${duplicates.length} ä¸ªé‡å¤å®šä¹‰çš„ç±»å‹:`, 'red')
    )

    duplicates.forEach(({ typeName, definitions }) => {
      console.warn(
        colorize(`\nğŸ”¸ ${typeName} (${definitions.length} å¤„å®šä¹‰):`, 'magenta')
      )
      definitions.forEach(def => {
        const relativePath = path.relative(process.cwd(), def.file)
        console.warn(`  ğŸ“„ ${relativePath}:${def.line} (${def.type})`)
      })
    })
  }

  console.warn(colorize('\nğŸ“ˆ æ ¸å¿ƒç±»å‹ä½¿ç”¨ç»Ÿè®¡:', 'yellow'))
  console.warn('================================')

  CORE_TYPES.forEach(coreType => {
    const definitions = typeDefinitions.get(coreType) || []
    const imports = typeImports.get(coreType) || []

    console.warn(colorize(`\nğŸ”¹ ${coreType}:`, 'cyan'))
    console.warn(`  å®šä¹‰æ¬¡æ•°: ${definitions.length}`)
    console.warn(`  å¯¼å…¥æ¬¡æ•°: ${imports.length}`)

    if (definitions.length > 1) {
      console.warn(colorize(`  âš ï¸  å­˜åœ¨é‡å¤å®šä¹‰`, 'yellow'))
    }

    if (imports.length === 0 && definitions.length > 0) {
      console.warn(colorize(`  âš ï¸  æœ‰å®šä¹‰ä½†æ— å¯¼å…¥ä½¿ç”¨`, 'yellow'))
    }
  })

  // æ˜¾ç¤ºæœªä½¿ç”¨ç±»å‹åˆ†æ
  if (unusedTypes.length > 0) {
    console.warn(colorize('\nğŸ—‘ï¸  æœªä½¿ç”¨çš„ç±»å‹å®šä¹‰:', 'yellow'))
    console.warn('================================')
    unusedTypes.forEach(({ typeName, definitions }) => {
      console.warn(colorize(`\nğŸ”¸ ${typeName}:`, 'magenta'))
      definitions.forEach(def => {
        const relativePath = path.relative(process.cwd(), def.file)
        console.warn(`  ğŸ“„ ${relativePath}:${def.line} (${def.type})`)
      })
    })
  }

  // æ˜¾ç¤ºç±»å‹ä¾èµ–å…³ç³»åˆ†æ
  console.warn(colorize('\nğŸ”— ç±»å‹ä¾èµ–å…³ç³»åˆ†æ:', 'yellow'))
  console.warn('================================')

  const { reverseDependencies } = dependencies
  const highlyDependedTypes = []

  reverseDependencies.forEach((dependents, typeName) => {
    if (dependents.size >= 3) {
      highlyDependedTypes.push({
        typeName,
        dependentCount: dependents.size,
        dependents: Array.from(dependents)
      })
    }
  })

  if (highlyDependedTypes.length > 0) {
    console.warn(colorize('\nğŸ“Š é«˜ä¾èµ–åº¦ç±»å‹ (è¢«3ä¸ªä»¥ä¸Šç±»å‹ä¾èµ–):', 'cyan'))
    highlyDependedTypes
      .sort((a, b) => b.dependentCount - a.dependentCount)
      .forEach(({ typeName, dependentCount, dependents }) => {
        console.warn(`  ğŸ”¸ ${typeName}: ${dependentCount} ä¸ªä¾èµ–`)
        console.warn(`    ä¾èµ–è€…: ${dependents.join(', ')}`)
      })
  } else {
    console.warn(colorize('âœ… æ²¡æœ‰å‘ç°é«˜ä¾èµ–åº¦çš„ç±»å‹', 'green'))
  }

  // ä¿å­˜è¯¦ç»†æŠ¥å‘Š
  const report = {
    timestamp: new Date().toISOString(),
    summary: {
      totalFiles: typeDefinitions.size,
      totalTypes: typeDefinitions.size,
      duplicateTypes: duplicates.length,
      unusedTypes: unusedTypes.length,
      coreTypeStats: CORE_TYPES.map(type => ({
        name: type,
        definitions: (typeDefinitions.get(type) || []).length,
        imports: (typeImports.get(type) || []).length,
        hasIssues: (typeDefinitions.get(type) || []).length > 1 ||
                   ((typeDefinitions.get(type) || []).length > 0 &&
                    (typeImports.get(type) || []).length === 0)
      })),
    },
    duplicates: duplicates.map(({ typeName, definitions }) => ({
      typeName,
      count: definitions.length,
      locations: definitions.map(def => ({
        file: path.relative(process.cwd(), def.file),
        line: def.line,
        type: def.type,
      })),
    })),
    unusedTypes: unusedTypes.map(({ typeName, definitions }) => ({
      typeName,
      locations: definitions.map(def => ({
        file: path.relative(process.cwd(), def.file),
        line: def.line,
        type: def.type,
      })),
    })),
    dependencies: {
      highlyDepended: highlyDependedTypes.map(({ typeName, dependentCount, dependents }) => ({
        typeName,
        dependentCount,
        dependents
      }))
    }
  }

  fs.writeFileSync('type-usage-report.json', JSON.stringify(report, null, 2))
  console.warn(
    colorize('\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: type-usage-report.json', 'green')
  )
}

// è¿è¡Œåˆ†æ
if (require.main === module) {
  generateReport()
}

module.exports = { analyzeProject, generateReport }
